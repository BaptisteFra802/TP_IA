{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMg7LCqIgUgu3WXeg7XJUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaptisteFra802/TP_IA/blob/main/randomforest_baptiste_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier CSV\n",
        "file_path = \"sensor_raw.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour examiner la structure des données\n",
        "df.head()\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Vérifier les types de données\n",
        "data_types = df.dtypes\n",
        "\n",
        "missing_values, data_types\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Séparer les caractéristiques (X) et la cible (y)\n",
        "X = df.drop(columns=[\"Target(Class)\"])\n",
        "y = df[\"Target(Class)\"]\n",
        "\n",
        "# Normalisation des caractéristiques\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Division en ensemble d'entraînement (80%) et de test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Vérifier la taille des ensembles\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialiser et entraîner le modèle Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Prédictions sur l'ensemble de test\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "accuracy, report\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5Iz9K1BKaV0",
        "outputId": "bff4f012-77a1-434a-c18f-c9ed3c28d26c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6860986547085202,\n",
              " '              precision    recall  f1-score   support\\n\\n           1       0.67      0.52      0.58        50\\n           2       0.69      0.62      0.65        58\\n           3       0.61      0.81      0.70        70\\n           4       0.87      0.76      0.81        45\\n\\n    accuracy                           0.69       223\\n   macro avg       0.71      0.68      0.69       223\\nweighted avg       0.70      0.69      0.68       223\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier CSV\n",
        "file_path = \"features_14.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour examiner la structure des données\n",
        "df.head()\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Vérifier les types de données\n",
        "data_types = df.dtypes\n",
        "\n",
        "missing_values, data_types\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Séparer les caractéristiques (X) et la cible (y)\n",
        "X = df.drop(columns=[\"Target\"])\n",
        "y = df[\"Target\"]\n",
        "\n",
        "# Normalisation des caractéristiques\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Division en ensemble d'entraînement (80%) et de test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Vérifier la taille des ensembles\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialiser et entraîner le modèle Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Prédictions sur l'ensemble de test\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "accuracy, report\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254eaf38-264f-46fd-84d1-89f2a8dc777b",
        "id": "A8xx0o1CMB_1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0,\n",
              " '              precision    recall  f1-score   support\\n\\n           1       1.00      1.00      1.00        50\\n           2       1.00      1.00      1.00        57\\n           3       1.00      1.00      1.00        70\\n           4       1.00      1.00      1.00        44\\n\\n    accuracy                           1.00       221\\n   macro avg       1.00      1.00      1.00       221\\nweighted avg       1.00      1.00      1.00       221\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}